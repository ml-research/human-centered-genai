<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="The recent popularity of text-to-image diffusion models (DM) can largely be attributed to the intuitive interface they provide to users. The intended generation can be expressed in natural language, with the model producing faithful interpretations of text prompts. However, expressing complex or nuanced ideas in text alone can be difficult. To ease image generation, we propose MultiFusion that allows one to express complex and nuanced concepts with arbitrarily interleaved inputs of multiple modalities and languages. MutliFusion leverages pre-trained models and aligns them for integration into a cohesive system, thereby avoiding the need for extensive training from scratch. Our experimental results demonstrate the efficient transfer of capabilities from individual modules to the downstream model. Specifically, the fusion of all independent components allows the image generation module to utilize multilingual, interleaved multimodal inputs despite being trained solely on monomodal data in a single language.">
    <meta property="og:title" content="MultiFusion - Project Page"/>
    <meta property="og:description" content="The recent popularity of text-to-image diffusion models (DM) can largely be attributed to the intuitive interface they provide to users. The intended generation can be expressed in natural language, with the model producing faithful interpretations of text prompts. However, expressing complex or nuanced ideas in text alone can be difficult. To ease image generation, we propose MultiFusion that allows one to express complex and nuanced concepts with arbitrarily interleaved inputs of multiple modalities and languages. MutliFusion leverages pre-trained models and aligns them for integration into a cohesive system, thereby avoiding the need for extensive training from scratch. Our experimental results demonstrate the efficient transfer of capabilities from individual modules to the downstream model. Specifically, the fusion of all independent components allows the image generation module to utilize multilingual, interleaved multimodal inputs despite being trained solely on monomodal data in a single language."/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="/diffusion-webpage/static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="MultiFusion - Project Page">
    <meta name="twitter:description" content="The recent popularity of text-to-image diffusion models (DM) can largely be attributed to the intuitive interface they provide to users. The intended generation can be expressed in natural language, with the model producing faithful interpretations of text prompts. However, expressing complex or nuanced ideas in text alone can be difficult. To ease image generation, we propose MultiFusion that allows one to express complex and nuanced concepts with arbitrarily interleaved inputs of multiple modalities and languages. MutliFusion leverages pre-trained models and aligns them for integration into a cohesive system, thereby avoiding the need for extensive training from scratch. Our experimental results demonstrate the efficient transfer of capabilities from individual modules to the downstream model. Specifically, the fusion of all independent components allows the image generation module to utilize multilingual, interleaved multimodal inputs despite being trained solely on monomodal data in a single language.">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="/diffusion-webpage/static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords"
          content="semantic guidance, image generation, text-to-image, stable diffusion, imagen, dall-e">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>MultiFusion</title>
    <link rel="icon" type="image/x-icon" href="/diffusion-webpage/static/images/favicon.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="/diffusion-webpage/static/css/bulma.min.css">
    <link rel="stylesheet" href="/diffusion-webpage/static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="/diffusion-webpage/static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="/diffusion-webpage/static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="/diffusion-webpage/static/css/index.css">
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="/diffusion-webpage/static/js/fontawesome.all.min.js"></script>
    <script src="/diffusion-webpage/static/js/bulma-carousel.min.js"></script>
    <script src="/diffusion-webpage/static/js/bulma-slider.min.js"></script>
    <script src="/diffusion-webpage/static/js/index.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</head>
<body>
<div style="margin: 10px">
    <a href="/diffusion-webpage/index.html"
       class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fa fa-home"></i>
                        </span>
        <span>Home</span>
    </a>
</div>
<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">MultiFusion: <br>Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation
                    </h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                  <a href="#"
                     target="_blank">Marco Bellagente<sup>*</sup></a>,
                        </span>
                        <span class="author-block">
                  <a href="https://www.aiml.informatik.tu-darmstadt.de/people/mbrack"
                     target="_blank">Manuel Brack<sup>*</sup></a>,
                        </span>
                        <span class="author-block">
                  <a href="https://www.aiml.informatik.tu-darmstadt.de/people/mbrack"
                     target="_blank">Hannah Teufel<sup>*</sup></a>,
                        </span>

                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Felix Friedrich</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Bj√∂rn Deiseroth</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Constantin Eichenberg</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Andrew Dai</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Robert Baldock</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">ouradeep Nanda</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Koen Oostermeijer</a>,
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/ffriedrich" target="_blank">Andres Felipe Cruz-Salinas</a>,
                  </span>
                        <span class="author-block">
                <a href="https://www.aiml.informatik.tu-darmstadt.de/people/pschramowski" target="_blank">Patrick Schramowski</a>,
                        </span>

                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/kkersting" target="_blank">Kristian Kersting,</a>
                  </span>
                        <span class="author-block">
                    <a href="https://www.aiml.informatik.tu-darmstadt.de/people/kkersting" target="_blank">Samuel Weinbach</a>
                  </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">DFKI, Aleph Alpha, hessian.AI, TU Darmstadt, LAION<br>Preprint under Review</span>
                         <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                        <a href="https://arxiv.org/2305.15296.pdf"
                           target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                  <a href="https://arxiv.org/abs/2305.15296" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        The recent popularity of text-to-image diffusion models (DM) can largely be attributed to the intuitive interface they provide to users. The intended generation can be expressed in natural language, with the model producing faithful interpretations of text prompts. However, expressing complex or nuanced ideas in text alone can be difficult. To ease image generation, we propose MultiFusion that allows one to express complex and nuanced concepts with arbitrarily interleaved inputs of multiple modalities and languages. MutliFusion leverages pre-trained models and aligns them for integration into a cohesive system, thereby avoiding the need for extensive training from scratch. Our experimental results demonstrate the efficient transfer of capabilities from individual modules to the downstream model. Specifically, the fusion of all independent components allows the image generation module to utilize multilingual, interleaved multimodal inputs despite being trained solely on monomodal data in a single language.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <!-- Your image here -->
                        <img src="" alt="MY ALT TEXT"/>
                        <h2 class="subtitle has-text-centered">

                        </h2>
                    </div>

            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->



<!-- Youtube video -->
<!--
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            &lt;!&ndash; Paper video. &ndash;&gt;
            <h2 class="title is-3">Video Presentation</h2>
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">

                    <div class="publication-video">
                        &lt;!&ndash; Youtube embed code here &ndash;&gt;
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/drkpQJpmyI0"
                                title="YouTube video player" frameborder="0"
                                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                                allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
-->
<!-- End youtube video -->


<!-- Video carousel -->

<!-- Paper poster -->
<!--<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container">
            <h2 class="title">Poster</h2>

            <iframe src="/diffusion-webpage/static/pdfs/cvpr23_poster_sld.pdf" width="100%" height="550">
            </iframe>

        </div>
    </div>
</section>-->
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{bellagente2023multifusion,
  author       = {Marco Bellagente and Manuel Brack and Hannah Teufel and Felix Friedrich and Bj√∂rn Deiseroth and Constantin Eichenberg and Andrew Dai and Robert Baldock and Souradeep Nanda and Koen Oostermeijer and Andres Felipe Cruz-Salinas and Patrick Schramowski and Kristian Kersting},
  title        = {MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation},
  journal      = {arXiv preprint arXiv:2305.15296},
  year         = {2023},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a>.
                        You are free to borrow the of this website, we just ask that you link back to this page in the
                        footer. <br> This website is licensed under a <a rel="license"
                                                                         href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                         target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
